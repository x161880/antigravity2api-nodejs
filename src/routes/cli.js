/**
 * Gemini CLI API 路由
 * 处理多种格式的端点：
 * - /cli/v1/chat/completions (OpenAI 格式)
 * - /cli/v1beta/models/:model:generateContent (Gemini 格式)
 * - /cli/v1beta/models/:model:streamGenerateContent (Gemini 流式格式)
 * - /cli/v1/messages (Claude 格式)
 *
 * 这是 Gemini CLI 反代的入口，支持 OpenAI/Gemini/Claude 兼容的 API 格式
 */

import { Router } from 'express';
import { handleGeminiCliRequest } from '../server/handlers/geminicli.js';
import logger from '../utils/logger.js';
import config from '../config/config.js';

const router = Router();

/**
 * 中间件：检查 Gemini CLI 功能是否启用
 */
const checkGeminiCliEnabled = (req, res, next) => {
  if (config.geminicli?.enabled === false) {
    return res.status(503).json({
      error: {
        message: 'Gemini CLI 功能未启用',
        type: 'service_unavailable',
        code: 'geminicli_disabled'
      }
    });
  }
  next();
};

// 应用中间件到所有路由
router.use(checkGeminiCliEnabled);

/**
 * 生成 Gemini CLI 可用模型列表
 * 与 gcli2api 项目保持一致
 */
function getGeminiCliModels() {
  const baseModels = [
    'gemini-2.5-pro',
    'gemini-2.5-flash',
    'gemini-3-pro-preview',
    'gemini-3-flash-preview'
  ];
  
  const models = [];
  const featurePrefixes = ['', '假流式/', '流式抗截断/'];
  const thinkingSuffixes = ['', '-maxthinking', '-nothinking'];
  const searchSuffix = '-search';
  
  for (const baseModel of baseModels) {
    for (const prefix of featurePrefixes) {
      // 基础模型
      models.push(`${prefix}${baseModel}`);
      
      // 带 thinking 后缀
      for (const thinkingSuffix of thinkingSuffixes) {
        if (thinkingSuffix) {
          models.push(`${prefix}${baseModel}${thinkingSuffix}`);
        }
      }
      
      // 带 search 后缀
      models.push(`${prefix}${baseModel}${searchSuffix}`);
      
      // 带 thinking + search 组合后缀
      for (const thinkingSuffix of thinkingSuffixes) {
        if (thinkingSuffix) {
          models.push(`${prefix}${baseModel}${thinkingSuffix}${searchSuffix}`);
        }
      }
    }
  }
  
  return models;
}

/**
 * 返回模型列表的通用处理函数
 */
function handleModelsRequest(req, res) {
  try {
    const created = Math.floor(Date.now() / 1000);
    const models = getGeminiCliModels();
    
    const modelList = {
      object: 'list',
      data: models.map(id => ({
        id,
        object: 'model',
        created,
        owned_by: 'google'
      }))
    };
    
    res.json(modelList);
  } catch (error) {
    logger.error('[GeminiCLI] 获取模型列表失败:', error.message);
    res.status(500).json({ error: error.message });
  }
}

/**
 * GET /cli/v1/models
 * 获取可用模型列表（OpenAI 格式）
 */
router.get('/v1/models', handleModelsRequest);

/**
 * GET /cli/v1beta/models
 * 获取可用模型列表（Gemini 格式）
 */
router.get('/v1beta/models', handleModelsRequest);

/**
 * POST /cli/v1/chat/completions
 * 处理 OpenAI 格式的聊天补全请求
 */
router.post('/v1/chat/completions', (req, res) => handleGeminiCliRequest(req, res, 'openai'));

// ==================== Gemini 格式端点 ====================

/**
 * POST /cli/v1beta/models/:model:generateContent
 * 处理 Gemini 格式的非流式请求
 */
router.post('/v1beta/models/:model\\:generateContent', (req, res) => {
  // 将模型名称添加到请求体
  req.body.model = req.params.model;
  handleGeminiCliRequest(req, res, 'gemini');
});

/**
 * POST /cli/v1beta/models/:model:streamGenerateContent
 * 处理 Gemini 格式的流式请求
 */
router.post('/v1beta/models/:model\\:streamGenerateContent', (req, res) => {
  // 将模型名称添加到请求体，并标记为流式
  req.body.model = req.params.model;
  req.body._isStream = true; // 内部标记
  handleGeminiCliRequest(req, res, 'gemini');
});

// ==================== Claude 格式端点 ====================

/**
 * POST /cli/v1/messages
 * 处理 Claude 格式的消息请求
 */
router.post('/v1/messages', (req, res) => handleGeminiCliRequest(req, res, 'claude'));

// ==================== 健康检查 ====================

/**
 * GET /cli/health
 * 健康检查端点
 */
router.get('/health', (req, res) => {
  res.json({
    status: 'ok',
    service: 'geminicli',
    enabled: config.geminicli?.enabled !== false,
    supportedFormats: ['openai', 'gemini', 'claude']
  });
});

export default router;